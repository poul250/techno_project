{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Парсим сайт avito.ru\n",
    "Фичи, которые будем вытаскивать с сайта:\n",
    "\n",
    "0 рублёф - неуказанная цена!!!!\n",
    "\n",
    "1) Дата регистрации\n",
    "2) Дата первого проданного товара\n",
    "3) По имени постараться определить пол, и смотреть, продаёт ли он одежду не соответствующую своему полу.\n",
    "4) Компания/Челокек\n",
    "5) Время ответа\n",
    "6) Среднее время между размещением товара, продажей, тыры пыры и тд\n",
    "7) Присутствие номера телефона и почты. ???\n",
    "8) Колисчество активных, завершенных товаров, отношение активных ко всем\n",
    "9) Наличие аватарки\n",
    "10) брать перцентиль (какой нибудь средний, шобы повыкидывать далёкие по цене)\n",
    "11) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from datetime import datetime, date, time\n",
    "from selenium import webdriver\n",
    "from time import sleep\n",
    "from functools import partial\n",
    "\n",
    "visited_products = None\n",
    "\n",
    "def random_sleep(offset=1, length=1):\n",
    "    sleep(random.random() * length + offset)\n",
    "    \n",
    "    \n",
    "def get_visited_products(path=None):\n",
    "    from os import path as path_\n",
    "    if path is None:\n",
    "        path = path_.join('data', 'visited_products.txt')\n",
    "    try:\n",
    "        with open(path, 'r') as file:\n",
    "            return set([product.strip() for product in file])\n",
    "    except IOError as e:\n",
    "        print('error in get_visited_products function: ', e)\n",
    "        return set()\n",
    "    \n",
    "\n",
    "def get_visited_accounts(directory='data', formatted='csv'):\n",
    "    import pandas as pd\n",
    "    import re\n",
    "    from glob import glob\n",
    "    from os import path\n",
    "    \n",
    "    try:\n",
    "        urls = set()\n",
    "        for file_name in glob(path.join(directory, '*.' + formatted)):\n",
    "            df = pd.read_csv(file_name)\n",
    "            for long_url in df.url:\n",
    "                url = re.match('(.*?profile).*', long_url).group(1)\n",
    "                urls.add(url)\n",
    "        return urls\n",
    "    except:\n",
    "        print('error in get_visited_accounts function')\n",
    "        return set()\n",
    "    \n",
    "    \n",
    "def visit_product(url, path=None):\n",
    "    from os import path as path_\n",
    "    if path is None:\n",
    "        path = path_.join('data', 'visited_products.txt')\n",
    "        \n",
    "    global visited_products\n",
    "    try:\n",
    "        visited_products.add(url)\n",
    "        with open(path, 'a') as file:\n",
    "            print(url, file=file)\n",
    "    except IOError as e:\n",
    "        print('error in visit_product function: ', e)\n",
    "\n",
    "        \n",
    "def get_acc_from_product(driver):\n",
    "    import re\n",
    "    long_url = driver.find_element_by_class_name('seller-info-name').find_element_by_tag_name('a').get_attribute('href')\n",
    "    try:\n",
    "        url = re.match(r\"https://www.avito.ru/user/(.*)/profile\", long_url).group(0)\n",
    "        return url\n",
    "    except:\n",
    "        return long_url\n",
    "    \n",
    "    \n",
    "def get_accounts_from_page(driver, url):\n",
    "    #данные о проверенных товарах\n",
    "    global visited_products\n",
    "    if visited_products is None:\n",
    "        visited_products = get_visited_products()\n",
    "\n",
    "    # Переходим на страничку, откуда будем вытаскивать аккаунты из товаров\n",
    "    driver.get(url)\n",
    "    random_sleep(1, 1)\n",
    "\n",
    "    # Берём ссылки на все товары и сохраняем в urls\n",
    "    products = driver.find_elements_by_class_name('item-description-title-link')\n",
    "    urls = []\n",
    "    for item in products:\n",
    "        urls.append(item.get_attribute('href'))\n",
    "    \n",
    "    # Ссылки, которые потом вернём\n",
    "    accounts_list = []\n",
    "        \n",
    "    for product_url in urls:\n",
    "        # Если не чекали етот товар раньше\n",
    "        if not (product_url in visited_products):\n",
    "            # Запомнить, что чекнули\n",
    "            visit_product(product_url)\n",
    "            \n",
    "            # Переходим по ссылке на товар\n",
    "            driver.get(product_url)\n",
    "            random_sleep(0, 0.3)\n",
    "            \n",
    "            # И пытаемся вытащить ссылку\n",
    "            try:\n",
    "                account_link = get_acc_from_product(driver)\n",
    "                accounts_list.append(account_link)\n",
    "            # Не получилось, и пофек\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    return accounts_list\n",
    "\n",
    "\n",
    "def filter_links(urls, accounts, HASH_MOD = 0):\n",
    "    '''Функция чекает список новых урлов на акки, отсеивает посещённые, оставляет нужные по хешу и тд и тп'''\n",
    "    from hashlib import md5\n",
    "    result = []\n",
    "    for url in urls:\n",
    "        if not (url in accounts) and url.startswith('https://www.avito.ru/user/') and \\\n",
    "                (int(md5(url.encode('utf-8')).hexdigest(), base=16) % 6 in HASH_MOD):\n",
    "            result.append(url)\n",
    "    return result\n",
    "\n",
    "\n",
    "def search(driver, url, HASH_MOD = [0], max_accounts = 0, start_page = 1):\n",
    "    '''url - ссылка на страничку авито, где есть товары и прокрутка страниц, чтобы можно было добавить\n",
    "    \"?p=<номер страницы> в конец url\n",
    "\n",
    "    max_accounts - максимальное количество аккаунтов, которое вытаскивает функция search '''\n",
    "    \n",
    "    # Вытаскиваем из папки data даные о уже обработанных акках.\n",
    "    visited_accounts = get_visited_accounts()\n",
    "    \n",
    "    # Номер страницы на avito\n",
    "    page = start_page\n",
    "    \n",
    "    # Счётчик заелдиных акков\n",
    "    yielded_accounts_counter = 0\n",
    "    \n",
    "    # ссылки на аккаунты, собранные со странички avito\n",
    "    links_from_page = []\n",
    "    \n",
    "    while True:\n",
    "        #Заелдили столько, сколко нужно\n",
    "        if yielded_accounts_counter >= max_accounts:\n",
    "            break\n",
    "            \n",
    "        # Во 1) што ты мне зделоеш, я в другом городе\n",
    "        # 2) Если прошли все акки в links_from_page, то берём новые со следующей страницы.\n",
    "        while len(links_from_page) == 0:\n",
    "            new_links = get_accounts_from_page(driver, url=(url + r'?p={}').format(page))\n",
    "            links_from_page = filter_links(new_links, visited_accounts, HASH_MOD)\n",
    "            page += 1\n",
    "            \n",
    "        account = links_from_page.pop()\n",
    "        visited_accounts.add(account)\n",
    "        yielded_accounts_counter += 1\n",
    "        yield account\n",
    "\n",
    "        \n",
    "def parse(browser, url):\n",
    "    browser.get(url)\n",
    "    name = browser.find_element_by_class_name('profile-public-name-edUBF')\n",
    "    data = browser.find_elements_by_class_name('profile-public-summary-item-wFbyw')\n",
    "    prod = browser.find_elements_by_class_name('styles-date-2vN1V')\n",
    "    cost = browser.find_elements_by_class_name('styles-price-1RC3V')\n",
    "    i = 0\n",
    "    l = len(prod) - 1\n",
    "    l2 = l\n",
    "    l3 = l2\n",
    "    while(l != len(prod)):\n",
    "        l3 = l2\n",
    "        l = len(prod)\n",
    "        l2 = l\n",
    "        browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        random_sleep()\n",
    "        prod = browser.find_elements_by_class_name('styles-date-2vN1V')\n",
    "        cost = browser.find_elements_by_class_name('styles-price-1RC3V')\n",
    "        try:\n",
    "            element = browser.find_element_by_class_name('styles-button-10MP4')\n",
    "            element.click()\n",
    "            l = l - 1\n",
    "            random_sleep()\n",
    "        except:\n",
    "            pass\n",
    "        if(l3 == len(prod)):\n",
    "            l = len(prod)\n",
    "    person_info = {\n",
    "        'url': url,\n",
    "        'name': name.text,\n",
    "        'data': list(map(lambda x: x.text, data)),\n",
    "        'prod_data_active': list(map(lambda x: x.text, prod)),\n",
    "        'prod_cost_active': list(map(lambda x: x.text, cost))\n",
    "    }\n",
    "    c = browser.find_element_by_partial_link_text('Завершённые')\n",
    "    c.click()\n",
    "    random_sleep()\n",
    "    prodold = browser.find_elements_by_class_name('styles-date-2vN1V')\n",
    "    costold = browser.find_elements_by_class_name('styles-price-1RC3V')\n",
    "    l = len(prodold) - 1\n",
    "    l2 = l\n",
    "    l3 = l2\n",
    "    while(l != len(prodold)):\n",
    "        l3 = l2\n",
    "        l = len(prodold)\n",
    "        l2 = l\n",
    "        browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        random_sleep()\n",
    "        prodold = browser.find_elements_by_class_name('styles-date-2vN1V')\n",
    "        costold = browser.find_elements_by_class_name('styles-price-1RC3V')\n",
    "        try:\n",
    "            element = browser.find_element_by_class_name('styles-button-10MP4')\n",
    "            element.click()\n",
    "            l = l - 1\n",
    "            random_sleep()\n",
    "        except:\n",
    "            pass\n",
    "        if(l3 == len(prod)):\n",
    "            l = len(prodold)\n",
    "    person_info['prod_data_finished'] = list(map(lambda x: x.text, prodold))\n",
    "    person_info['prod_cost_finished'] = list(map(lambda x: x.text, costold))\n",
    "    return person_info\n",
    "\n",
    "\n",
    "def strtodays(s):\n",
    "    import re\n",
    "    from datetime import date, timedelta\n",
    "    months = ['января', 'февраля', 'марта', 'апреля', 'мая', 'июня',\n",
    "                  'июля', 'августа', 'сентября', 'октября', 'ноября', 'декабря'] \n",
    "    \n",
    "    if s.lower().find('сегодня') >= 0:\n",
    "        t = date.today()\n",
    "        return date(t.year, t.month, t.day).toordinal()\n",
    "    elif s.lower().find('вчера') >= 0:\n",
    "        t = date.today() - timedelta(days=1)\n",
    "        return date(t.year, t.month, t.day).toordinal()\n",
    "    \n",
    "    m = re.match(r'.*(\\d\\d\\d\\d).*', s)\n",
    "    year = date.today().year if m is None else int(m.group(1))\n",
    "    month = 0\n",
    "    for i in range(12):\n",
    "        if s.find(months[i]) >= 0:\n",
    "            month = i + 1\n",
    "            break\n",
    "    day = int(re.match(r'(\\d*) .*', s).groups(1)[0])\n",
    "\n",
    "    return date(year, month, day).toordinal()\n",
    "\n",
    "\n",
    "def normalize(account):\n",
    "    import re\n",
    "    from datetime import date, timedelta\n",
    "    \n",
    "    result = dict()\n",
    "    result['name'] = account['name'].lower()\n",
    "    result['person_status'] = account['data'][0].lower()\n",
    "    result['url'] = account['url']\n",
    "    \n",
    "    start_date = account['data'][1]\n",
    "    if start_date.startswith('На Авито с '):\n",
    "        months = ['января', 'февраля', 'марта', 'апреля', 'мая', 'июня',\n",
    "                  'июля', 'августа', 'сентября', 'октября', 'ноября', 'декабря'] \n",
    "        month = 0\n",
    "        for i in range(12):\n",
    "            if start_date.find(months[i]) >= 0:\n",
    "                month = i + 1\n",
    "                break\n",
    "        result['start_date'] = str(date(int(re.match('.*(\\d\\d\\d\\d).*', start_date).group(1)), month, 1).toordinal())\n",
    "    else:\n",
    "        result['start_date'] = ''\n",
    "        \n",
    "    result['answer_time'] = account['data'][3]\n",
    "    result['first_sold_time'] = '' if len(account['prod_data_finished']) == 0 else str(strtodays(account['prod_data_finished'][-1]))\n",
    "    result['n_active'] = str(len(account['prod_data_active']))\n",
    "    result['n_finished'] = str(len(account['prod_data_finished']))\n",
    "    result['active_finished_ratio'] = str((len(account['prod_data_active']) + 1) / (len(account['prod_data_finished']) + 1))\n",
    "    \n",
    "    active_costs = []\n",
    "    for cost in account['prod_cost_active']:\n",
    "        active_costs.append(int(re.match('(\\d*).*', cost.replace(' ', '')).group(1)))\n",
    "        \n",
    "    finished_costs = []\n",
    "    for cost in account['prod_cost_finished']:\n",
    "        finished_costs.append(int(re.match('(\\d*).*', cost.replace(' ', '')).group(1)))\n",
    "        \n",
    "    result['min_active_cost'] = str(min(active_costs)) if len(active_costs) > 0 else ''\n",
    "    result['max_active_cost'] = str(max(active_costs)) if len(active_costs) > 0 else ''\n",
    "    result['mean_active_cost'] = str(sum(active_costs) / len(active_costs)) if len(active_costs) > 0 else ''\n",
    "    \n",
    "    result['min_finished_cost'] = str(min(finished_costs)) if len(finished_costs) > 0 else ''\n",
    "    result['max_finished_cost'] = str(max(finished_costs)) if len(finished_costs) > 0 else ''\n",
    "    result['mean_finished_cost'] = str(sum(finished_costs) / len(finished_costs)) if len(finished_costs) > 0 else ''\n",
    "    return result\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "from os import path\n",
    "if __name__ == '__main__':\n",
    "    max_accounts = 3000\n",
    "    url = r'https://www.avito.ru/rossiya/lichnye_veschi'\n",
    "    data = {}\n",
    "    browser = webdriver.Chrome()\n",
    "    parser = partial(parse, browser)\n",
    "    searcher = search(driver=browser, url=url, max_accounts=max_accounts)\n",
    "    for key, item in normalize(parser(next(searcher))).items():\n",
    "        data[key] = [item]\n",
    "    counter = 0\n",
    "    cntr = 0\n",
    "    while(cntr < max_accounts):\n",
    "        try:\n",
    "            for acc_data in map(parser, searcher):\n",
    "                if(counter == 15):\n",
    "                    df.to_csv(path.join('data', 'avito_data2.csv'))\n",
    "                counter += 1\n",
    "                counter %= 30\n",
    "                cntr += 1\n",
    "                for key, item in normalize(acc_data).items():\n",
    "                    data[key].append(item)\n",
    "                df = pd.DataFrame(data)\n",
    "                if(counter == 0):\n",
    "                    df.to_csv(path.join('data', r'avito_data{}.csv').format(str(datetime.now()).replace(':', '.')))\n",
    "                    for key in data.keys():\n",
    "                        data[key] = []\n",
    "                print(cntr)\n",
    "        except:\n",
    "            df.to_csv(path.join('data', r'avito_data{}.csv').format(str(datetime.now()).replace(':', '.')))\n",
    "            for key in data.keys():\n",
    "                data[key] = []\n",
    "            random_sleep(60, 60)\n",
    "            cntr += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
